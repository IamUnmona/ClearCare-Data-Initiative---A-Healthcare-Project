{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc5e5064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Processing: 930430029_Hillsboro-Medical-Center_standardcharges.csv\n",
      "‚úÖ Saved: /Users/unmonadas/Desktop/Cleaned_Tall_CSVs_Fixed/Cleaned_Hillsboro_Medical_Center_0.csv\n",
      "üìÑ Processing: 590634433-1245520386_Nemours-Childrens-Hospital_standardcharges(1).csv\n",
      "‚úÖ Saved: /Users/unmonadas/Desktop/Cleaned_Tall_CSVs_Fixed/Cleaned_Nemours_Childrens_Health_Winter_Garden_1.csv\n",
      "üìÑ Processing: 590634433-1245520386_Nemours-Childrens-Hospital_standardcharges(2).csv\n",
      "‚úÖ Saved: /Users/unmonadas/Desktop/Cleaned_Tall_CSVs_Fixed/Cleaned_Nemours_Childrens_Health_Lake_Mary_2.csv\n",
      "üìÑ Processing: 590634433-1245520386_Nemours-Childrens-Hospital_standardcharges.csv\n",
      "‚úÖ Saved: /Users/unmonadas/Desktop/Cleaned_Tall_CSVs_Fixed/Cleaned_Nemours_Childrens_Hospital_Orlando_3.csv\n",
      "üìÑ Processing: 931176109_Oregon-Health-and-Science-University_standardcharges.csv\n",
      "‚úÖ Saved: /Users/unmonadas/Desktop/Cleaned_Tall_CSVs_Fixed/Cleaned_Oregon_Health_&_Science_University_4.csv\n",
      "üìÑ Processing: 930429015_Adventist-Health-Portland_standardcharges.csv\n",
      "‚úÖ Saved: /Users/unmonadas/Desktop/Cleaned_Tall_CSVs_Fixed/Cleaned_Adventist_Portland_5.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "FINAL_COLUMNS = [\n",
    "    'hospital_name', 'street_address', 'city', 'state', 'zip_code',\n",
    "    'description', 'billing_code', 'billing_code_type', 'standard_charge',\n",
    "    'discounted_cash_charge', 'payer_name', 'plan_name',\n",
    "    'negotiated_dollar', 'negotiated_percentage', 'estimated_amount',\n",
    "    'min_charge', 'max_charge'\n",
    "]\n",
    "\n",
    "def clean_single_tall_csv(filepath):\n",
    "    # Read first two rows to extract metadata\n",
    "    try:\n",
    "        raw_meta = pd.read_csv(filepath, nrows=2, header=None, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        raw_meta = pd.read_csv(filepath, nrows=2, header=None, encoding='latin1')\n",
    "\n",
    "    hospital_name = str(raw_meta.iloc[1, 0]).strip().title()\n",
    "    full_address = str(raw_meta.iloc[1, 4]).strip()\n",
    "\n",
    "    if ',' in full_address:\n",
    "        parts = [p.strip() for p in full_address.split(',')]\n",
    "        street_address = parts[0]\n",
    "        city = parts[1] if len(parts) > 1 else ''\n",
    "        state_zip = parts[2].split() if len(parts) > 2 else []\n",
    "        state = state_zip[0] if len(state_zip) > 0 else ''\n",
    "        zip_code = state_zip[1] if len(state_zip) > 1 else ''\n",
    "    else:\n",
    "        street_address = full_address\n",
    "        city = state = zip_code = ''\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, header=2, encoding='utf-8', low_memory=False)\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(filepath, header=2, encoding='latin1', low_memory=False)\n",
    "\n",
    "    # Filter CPT-coded rows\n",
    "    cpt_cols = [col for col in df.columns if 'code' in col.lower() and 'type' in col.lower()]\n",
    "    cpt_rows = pd.Series([False] * len(df))\n",
    "    for col in cpt_cols:\n",
    "        cpt_rows |= df[col].astype(str).str.upper().str.contains('CPT', na=False)\n",
    "\n",
    "    df = df[cpt_rows]\n",
    "\n",
    "    for n in range(1, 5):\n",
    "        code_col = f'code|{n}'\n",
    "        type_col = f'code|{n}|type'\n",
    "        if code_col in df.columns and type_col in df.columns:\n",
    "            mask = df[type_col].astype(str).str.upper() == 'CPT'\n",
    "            df.loc[mask, 'billing_code'] = df.loc[mask, code_col]\n",
    "            df.loc[mask, 'billing_code_type'] = df.loc[mask, type_col]\n",
    "\n",
    "    column_map = {\n",
    "        'description': 'description',\n",
    "        'standard_charge|gross': 'standard_charge',\n",
    "        'standard_charge|discounted_cash': 'discounted_cash_charge',\n",
    "        'payer_name': 'payer_name',\n",
    "        'plan_name': 'plan_name',\n",
    "        'standard_charge|negotiated_dollar': 'negotiated_dollar',\n",
    "        'standard_charge|negotiated_percentage': 'negotiated_percentage',\n",
    "        'estimated_amount': 'estimated_amount',\n",
    "        'standard_charge|min': 'min_charge',\n",
    "        'standard_charge|max': 'max_charge'\n",
    "    }\n",
    "\n",
    "    df = df[[col for col in df.columns if col in column_map or col in ['billing_code', 'billing_code_type', 'description']]]\n",
    "    df.rename(columns=column_map, inplace=True)\n",
    "\n",
    "    for col in FINAL_COLUMNS:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "\n",
    "    # Assign metadata columns\n",
    "    df['hospital_name'] = hospital_name\n",
    "    df['street_address'] = street_address\n",
    "    df['city'] = city\n",
    "    df['state'] = state\n",
    "    df['zip_code'] = zip_code\n",
    "\n",
    "    df = df[FINAL_COLUMNS].drop_duplicates()\n",
    "    return df, hospital_name\n",
    "\n",
    "\n",
    "def batch_clean_tall_csvs(input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for i, filename in enumerate(os.listdir(input_folder)):\n",
    "        if filename.endswith('.csv'):\n",
    "            filepath = os.path.join(input_folder, filename)\n",
    "            print(f\"üìÑ Processing: {filename}\")\n",
    "            try:\n",
    "                df_cleaned, hosp_name = clean_single_tall_csv(filepath)\n",
    "                if df_cleaned.empty:\n",
    "                    print(f\"‚ö†Ô∏è No CPT-coded entries in {filename}\")\n",
    "                    continue\n",
    "                safe_name = hosp_name.replace('/', '_').replace(' ', '_')\n",
    "                output_path = os.path.join(output_folder, f\"Cleaned_{safe_name}_{i}.csv\")\n",
    "                df_cleaned.to_csv(output_path, index=False)\n",
    "                print(f\"‚úÖ Saved: {output_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error in {filename}: {e}\")\n",
    "\n",
    "# USAGE\n",
    "batch_clean_tall_csvs(\n",
    "    input_folder='/Users/unmonadas/Desktop/TALL CSV RAW/OneDrive_1_5-5-2025',\n",
    "    output_folder='/Users/unmonadas/Desktop/Cleaned_Tall_CSVs_Fixed'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caba9bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
